#r <- r + 1
}
})
system.time({
# the burn-in iterations
for(r in  1:env$gNCREP)
{
if(env$gNIV > 0) {
out    <- nextB(a, b, d, p, f, env)
b      <- out[[1]]
accept <- out[[2]]
p      <- out[[3]]
#a <- nextA(b, d, env)
# this constrains the means of the random parameters to be user-specified
# this is necessary for such things as error components logit.
#if(!is.null(env$fixedA))
#{
#     for(rp in 1:env$gNIV)
#     {
#          if(!is.na(env$fixedA[rp]))
#          {
#               a[rp] <- env$fixedA[rp]
#          }
#     }
#}
#if(env$gFULLCV==1) {
#     d <- nextD(a, b, env)
#}
#if(env$gFULLCV==0) {
#     d <- nextDind(a, b, env)
#}
}
# drawing a new set of fixed coefficients
if(env$gFIV > 0) {
out <- nextF(p,f,b,env)
f  <- out[[1]]
p  <- out[[2]]
}
#if(r%%env$gINFOSKIP == 0) {
#     writeLog(r,p,a,b,d,f,env)
#}
######@@@@@@@@@@@@@@@@
#@@@@@@@@@@
#r <- r + 1
}
})
likelihood <- function(fc,b,env)
{
if(env$gNIV>0)
{
gIDS <- env$gIDS
C    <- trans(b,env)
C    <- C[gIDS,]
}
p <- likelihood_user(fc,C)
p.temp <- data.table(gIDS,p)
setkey(p.temp,gIDS)
p0     <- p.temp[,prod(p),by=gIDS]$V1
p0     <- replace(p0,is.nan(p0),1e-32)
return(p0)
}
system.time({
# the burn-in iterations
for(r in  1:env$gNCREP)
{
if(env$gNIV > 0) {
out    <- nextB(a, b, d, p, f, env)
b      <- out[[1]]
accept <- out[[2]]
p      <- out[[3]]
#a <- nextA(b, d, env)
# this constrains the means of the random parameters to be user-specified
# this is necessary for such things as error components logit.
#if(!is.null(env$fixedA))
#{
#     for(rp in 1:env$gNIV)
#     {
#          if(!is.na(env$fixedA[rp]))
#          {
#               a[rp] <- env$fixedA[rp]
#          }
#     }
#}
#if(env$gFULLCV==1) {
#     d <- nextD(a, b, env)
#}
#if(env$gFULLCV==0) {
#     d <- nextDind(a, b, env)
#}
}
# drawing a new set of fixed coefficients
if(env$gFIV > 0) {
out <- nextF(p,f,b,env)
f  <- out[[1]]
p  <- out[[2]]
}
#if(r%%env$gINFOSKIP == 0) {
#     writeLog(r,p,a,b,d,f,env)
#}
######@@@@@@@@@@@@@@@@
#@@@@@@@@@@
#r <- r + 1
}
})
p <- env$likelihood(f,b,env)
system.time({
# the burn-in iterations
for(r in  1:env$gNCREP)
{
if(env$gNIV > 0) {
out    <- nextB(a, b, d, p, f, env)
b      <- out[[1]]
accept <- out[[2]]
p      <- out[[3]]
#a <- nextA(b, d, env)
# this constrains the means of the random parameters to be user-specified
# this is necessary for such things as error components logit.
#if(!is.null(env$fixedA))
#{
#     for(rp in 1:env$gNIV)
#     {
#          if(!is.na(env$fixedA[rp]))
#          {
#               a[rp] <- env$fixedA[rp]
#          }
#     }
#}
#if(env$gFULLCV==1) {
#     d <- nextD(a, b, env)
#}
#if(env$gFULLCV==0) {
#     d <- nextDind(a, b, env)
#}
}
# drawing a new set of fixed coefficients
if(env$gFIV > 0) {
out <- nextF(p,f,b,env)
f  <- out[[1]]
p  <- out[[2]]
}
#if(r%%env$gINFOSKIP == 0) {
#     writeLog(r,p,a,b,d,f,env)
#}
######@@@@@@@@@@@@@@@@
#@@@@@@@@@@
#r <- r + 1
}
})
12.85/100
system.time({
for(i in 1:100)
{
p <- likelihood_user(f,C)
}})
12-8
gVarNamesNormal <- c(
"QoL1_2",
"QoL1_3",
"QoL1_4",
"QoL1_5",
"QoL2_2",
"QoL2_3",
"QoL2_4",
"QoL2_5",
"QoL3_2",
"QoL3_3",
"QoL3_4",
"QoL3_5",
"QoL4_2",
"QoL4_3",
"QoL4_4",
"QoL4_5",
"QoL5_2",
"QoL5_3",
"QoL5_4",
"QoL5_5",
"QoL6_2",
"QoL6_3",
"QoL6_4",
"QoL6_5",
"QoL7_2",
"QoL7_3",
"QoL7_4",
"QoL7_5",
"Duration"
)
gVarNamesNormal
length(gVarNamesNormal)
gNIV=29
md <- matrix(0,nrow=gNIV*(gNIV+1)/2,ncol=gNEREP)
gc()
t1<- matrix(0,nrow=2,ncol=3)
colnames(t1)
colnames(t1) <- c("col1","col2","col3")
t1
write.table(t1,"C:\\work\\test.csv",sep=",")
library(RSGHB)
# ------------------
# Code for a Multinomial Logit Model with Log-normal Random Coefficients
#
# Jeff Dumont
#
# ------------------
library(RSGHB)
setwd("C:/Work/Code/HB/Examples/Basic Example - MNL with log-normal pararmeters")     		    # working directory
# ------------------
# DATA PREPARATION
# ------------------
# assumes that respondents are identified with a ID column
# also assumes that the data is sorted by respondent then experiment
choicedata <- read.table("Data_simulated.csv",sep=",",header=T)
# Specify any variables here that you'd like to use in the
# utility equations in the likelihood function below
# These can be any variables within the data or transformations of
# those variables
x1 <- choicedata$x1
x2 <- choicedata$x2
x3 <- choicedata$x3
y1 <- choicedata$y1
y2 <- choicedata$y2
y3 <- choicedata$y3
# The choice vectors
# Dummying coding the choice vector allows for easier coding of the
# the likelihood calculations. So we will have one column for each
# alternative in the design
choice1    <- (choicedata$choice==1)
choice2    <- (choicedata$choice==2)
choice3    <- (choicedata$choice==3)
# ------------------
# ESTIMATION CONTROL
# Setting control list for estimation
# ?doHB for more estimation options
# ------------------
modelname <- "MNL_withLogNormals"          # used for output
# Names for the random variables
gVarNamesNormal <- c("Bx","By")
# Fixed Variables
gVarNamesFixed <- c()
# For each variable, specify the distribution for its coefficient
# The options are:
# 1. normal
# 2. log-nomal
# 3. negative log-normal
# 4. normal with all values below zero massed at zero
# 5. Johnson SB with a specified min and max
# gDIST must have an entry for each value in gVarNamesNormal
gDIST <- c(2,3)
# STARTING VALUES
svN <- c(-3,-3)            # for the random coefficients
# The selection of the mean here is important when working with non-normal distributions
# ITERATION SETTINGS
gNCREP    <- 10000  	  # Number of iterations to use prior to convergence
gNEREP    <- 10000 	       # Number of iterations to keep for averaging after convergence has been reached
gNSKIP    <- 1			  # Number of iterations to do in between retaining draws for averaging
gINFOSKIP <- 250           # How frequently to print info about the iteration process
# CONTROL LIST TO PASS TO doHB
control <- list(
modelname=modelname,
gVarNamesNormal=gVarNamesNormal,
gDIST=gDIST,
svN=svN,
gNCREP=gNCREP,
gNEREP=gNEREP,
gNSKIP=gNSKIP,gINFOSKIP=gINFOSKIP
)
# ------------------
# likelihood
# USE:     Calculates the likelihood of choice | B
#          Returns likelihood values for each observation
# NOTES:   This is where the bulk of the computation resides so coding this efficiently
#          is essential to reducing run time.
# ------------------
likelihood <- function(fc,b)
{
cc <- 1
Bx <- b[,cc];cc<-cc+1
By <- b[,cc];cc<-cc+1
v1 <- Bx * x1 + By * y1
v2 <- Bx * x2 + By * y2
v3 <- Bx * x3 + By * y3
p <- (exp(v1)*choice1 + exp(v2)*choice2 + exp(v3)*choice3) / (exp(v1) + exp(v2) + exp(v3))
return(p)
}
# Estimate the model
doHB(likelihood, choicedata, control)
# ------------------
# Code for a Ordered Probit with Random Coefficients and
# Fixed Thresholds
#
# Jeff Dumont
#
# ------------------
library(RSGHB)
# ------------------
# Global Settings
# ------------------
setwd("C:\\Work\\Code\\HB\\Examples\\Basic Example - Ordered Probit")     		    # working directory
# ------------------
# DATA PREPARATION
# ------------------
# assumes that respondents are identified with a ID column
# also assumes that the data is sorted by respondent then experiment
choicedata <- read.table("Data_simulated.csv",sep=",",header=T)
# Specify any variables here that you'd like to use in the
# utility equations in the likelihood function below
# These can be any variables within the data or transformations of
# those variables
x1 <- choicedata$x1
y1 <- choicedata$y1
# The choice vectors
# Dummying coding the choice vector allows for easier coding of the
# the likelihood calculations. So we will have one column for each
# alternative in the design
choice1    <- (choicedata$choice==1)
choice2    <- (choicedata$choice==2)
choice3    <- (choicedata$choice==3)
# ------------------
# ESTIMATION CONTROL
# Setting control list for estimation
# ?doHB for more estimation options
# ------------------
modelname <- "Ordered_Probit"		# used for output
# Names for the random variables
gVarNamesNormal <- c("Bx","By")
# Names for the random variables
gVarNamesFixed <- c("threshold1","threshold2")
# For each variable, specify the distribution for its coefficient
# The options are:
# 1. normal
# 2. log-nomal
# 3. negative log-normal
# 4. normal with all values below zero massed at zero
# 5. Johnson SB with a specified min and max
# gDIST must have an entry for each value in gVarNamesNormal
gDIST <- c(1,1)
# STARTING VALUES
FC <- c(0,1)                  # for the fixed coefficients
svN <- c(0,0)            # for the random coefficients
# The selection of the mean here is important when working with non-normal distributions
# ITERATION SETTINGS
gNCREP    <- 10000  	  # Number of iterations to use prior to convergence
gNEREP    <- 10000 	       # Number of iterations to keep for averaging after convergence has been reached
gNSKIP    <- 1			  # Number of iterations to do in between retaining draws for averaging
gINFOSKIP <- 250           # How frequently to print info about the iteration process
# CONTROL LIST TO PASS TO doHB
control <- list(
modelname=modelname,
gVarNamesNormal=gVarNamesNormal,
gDIST=gDIST,
svN=svN,
gVarNamesFixed=gVarNamesFixed,
FC=FC,
gNCREP=gNCREP,
gNEREP=gNEREP,
gNSKIP=gNSKIP,gINFOSKIP=gINFOSKIP
)
# ------------------
# likelihood
# USE:     Calculates the likelihood of choice | B
#          Returns likelihood values for each observation
# NOTES:   This is where the bulk of the computation resides so coding this efficiently
#          is essential to reducing run time.
# ------------------
likelihood <- function(fc,b)
{
cc <- 1
Bx <- b[,cc];cc <- cc + 1
By <- b[,cc];cc <- cc + 1
cc <- 1
threshold1 <- fc[cc];cc <- cc + 1
threshold2 <- fc[cc];cc <- cc + 1
v1 <- Bx * x1 + By * y1
p <- (pnorm(threshold1-v1) - pnorm(-300-v1)      ) * choice1 +
(pnorm(threshold2-v1) - pnorm(threshold1-v1)) * choice2 +
(pnorm(300-v1)        - pnorm(threshold2-v1)) * choice3
return(p)
}
# Estimate the model
doHB(likelihood, choicedata, control)
data <- cbind(rep(1:4000,4),runif(4*4000))
colnames(data) <- c("id","data")
temp <- matrix(0,nrow=16000,ncol=16000)
temp[cbind(data[,1],1:16000)]<-exp(data[,2])
rowSums(temp)
system.time({
for(i in 1:10)
{
rowSums(temp)[1:4000]
}
})
system.time({
for(i in 1:10)
{
aggregate(data[,2],by=list(data[,1]),prod)
}
})
.Call()
?.Call()
?C
?.C
dyn.load("RSGHB")
dyn.load("RSGHB")
as.integer
?replace
is.na(NA)
# ------------------
# Code for a Nested Logit Model
# This assumes that alt 1 and 2 are nested together and alternatives
# 3 and 4 are nested together
#
# Jeff Dumont
#
# Requires
# data.table package
# ------------------
library(RSGHB)
setwd("C:\\Work\\Code\\HB\\RSGHB.git\\Examples\\Advanced Example - Nested Logit")     		    # working directory
# ------------------
# DATA PREPARATION
# ------------------
# assumes that respondents are identified with a ID column
# also assumes that the data is sorted by respondent then experiment
choicedata <- read.table("Data_simulated.csv",sep=",",header=T)
# Specify any variables here that you'd like to use in the
# utility equations in the likelihood function below
# These can be any variables within the data or transformations of
# those variables
x1 <- choicedata$x1
x2 <- choicedata$x2
x3 <- choicedata$x3
x4 <- choicedata$x4
y1 <- choicedata$y1
y2 <- choicedata$y2
y3 <- choicedata$y3
y4 <- choicedata$y4
# The choice vectors
# Dummying coding the choice vector allows for easier coding of the
# the likelihood calculations. So we will have one column for each
# alternative in the design
choice1    <- (choicedata$choice==1)
choice2    <- (choicedata$choice==2)
choice3    <- (choicedata$choice==3)
choice4    <- (choicedata$choice==4)
# ------------------
# ESTIMATION CONTROL
# Setting control list for estimation
# ?doHB for more estimation options
# ------------------
modelname <- "Nested_Logit"     	# used for output
# Names for the normal variables
gVarNamesNormal <- c("Bx","By")
# For each variable, specify the distribution for its coefficient
# The options are:
# 1. normal
# 2. log-nomal
# 3. negative log-normal
# 4. normal with all values below zero massed at zero
# 5. Johnson SB with a specified min and max
# gDIST must have an entry for each value in gVarNamesNormal
gDIST <- c(1,1)
# Names for the fixed variables
gVarNamesFixed <- c("lambda1","lambda2")
# STARTING VALUES
svN <- c(0,0)                 # for the random coefficients
FC  <- c(0.5,0.5)             # for the fixed coefficients
# ITERATION SETTINGS
gNCREP    <- 10000  	  # Number of iterations to use prior to convergence
gNEREP    <- 10000 	       # Number of iterations to keep for averaging after convergence has been reached
gNSKIP    <- 1			  # Number of iterations to do in between retaining draws for averaging
gINFOSKIP <- 250           # How frequently to print info about the iteration process
control <- list(
modelname=modelname,
gVarNamesNormal=gVarNamesNormal,
gVarNamesFixed=gVarNamesFixed,
svN=svN,
FC=FC,
gDIST=gDIST,
gNCREP=gNCREP,
gNEREP=gNEREP,
gNSKIP=gNSKIP,
gINFOSKIP=gINFOSKIP
)
# ------------------
# likelihood
# USE:     Calculates the likelihood of choice | B
#          Returns likelihood values for each observation
# NOTES:   This is where the bulk of the computation resides so coding this efficiently
#          is essential to reducing run time.
# ------------------
likelihood <- function(fc,b)
{
cc <- 1
Bx <- b[,cc];cc <- cc + 1
By <- b[,cc];
cc <- 1
lambda1 <- fc[cc];cc <- cc + 1
lambda2 <- fc[cc];
v1 <- Bx * x1 + By * y1
v2 <- Bx * x2 + By * y2
v3 <- Bx * x3 + By * y3
v4 <- Bx * x4 + By * y4
# assuming alternatives 1 and 2 are nested together and
# alternative 3 and 4 are nested together
logsum1 <- log(exp(v1/lambda1) + exp(v2/lambda1))
logsum2 <- log(exp(v3/lambda2) + exp(v4/lambda2))
prob.nest <- (exp(lambda1 * logsum1) * (choice1 + choice2) + exp(lambda2 * logsum2) * (choice3 + choice4))/(exp(lambda1 * logsum1) + exp(lambda2 * logsum2))
prob.withinnest <- (choice1 * exp(v1/lambda1) + choice2 * exp(v2/lambda1))/(exp(v1/lambda1)+exp(v2/lambda1)) + (choice3 * exp(v3/lambda2) + choice4 * exp(v4/lambda2))/(exp(v3/lambda2)+exp(v4/lambda2))
p <- prob.nest * prob.withinnest
return(p)
}
# Estimate the model
doHB(likelihood, choicedata, control)
